{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4962d8a",
   "metadata": {},
   "source": [
    "Practical Task for Ensemble Algorithms\n",
    "\n",
    "Practical Task: \n",
    "Complete these two questions given below using the “german_data_creditcard.csv” dataset. Please send the python code which you prepared to complete the tasks below with explanations of your results.\n",
    "1.\tReport the best hypermeters which used to run Random Forest algorithm. Explain your results.\n",
    "2.\tRun Adaboost and GB on the given data and compare. Explain your results.\n",
    "\n",
    "RandomForestClassifier — scikit-learn 1.8.0 documentation\n",
    "GradientBoostingClassifier — scikit-learn 1.8.0 documentation\n",
    "AdaBoostClassifier — scikit-learn 1.8.0 documentation\n",
    "GridSearchCV — scikit-learn 1.8.0 documentation\n",
    "Note: You can take the help of given python code also go through the below reference link to understand the concept.\n",
    "Bagging and boosting\n",
    "https://analyticsindiamag.com/primer-ensemble-learning-bagging-sboosting/#:~:text=Bagging%20is%20a%20way%20to,based%20on%20the%20last%20classification.\n",
    "A Primer to Ensemble Learning – Bagging and Boosting (analyticsindiamag.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7717ad",
   "metadata": {},
   "source": [
    "1.\tReport the best hypermeters which used to run Random Forest algorithm. Explain your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cd3912a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 16)\n",
      "Index(['Creditability', 'Acc_Bal_bin', 'Pay_Status_bin', 'Value_SavStock_bin',\n",
      "       'Length_Emp_bin', 'S&M_Status_bin', 'No_of_Credits_bin',\n",
      "       'Co_Credits_bin', 'Purpose_bin', 'Telephone_bin', 'Instalment_bin',\n",
      "       'Apartment_bin', 'Most_Val_Asset_bin', 'Duration_Credit',\n",
      "       'Credit_Amount', 'Age_bin'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"german_data_creditcard.csv\")\n",
    "\n",
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "994c7328",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Features and Target\n",
    "x = df.drop(\"Creditability\", axis=1)\n",
    "y = df[\"Creditability\"]\n",
    "\n",
    "x = pd.get_dummies(x, drop_first=True)\n",
    "\n",
    "#Train-Test Split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.30, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ca9814d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Accuracy: 0.7557142857142857\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [None, 5, 10, 20],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "print(\"Parameters:\", grid_search.best_params_)\n",
    "print(\"Accuracy:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "958842b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Test Accuracy: 0.7533333333333333\n",
      "[[ 35  55]\n",
      " [ 19 191]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.39      0.49        90\n",
      "           1       0.78      0.91      0.84       210\n",
      "\n",
      "    accuracy                           0.75       300\n",
      "   macro avg       0.71      0.65      0.66       300\n",
      "weighted avg       0.74      0.75      0.73       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Get best Random Forest\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "y_pred_rf = best_rf.predict(x_test)\n",
    "\n",
    "print(\"Random Forest Test Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc71bcf",
   "metadata": {},
   "source": [
    "Random Forest is a method that builds decision trees and combine them to make desition.It helps to maintain stability and reduce overfitting\n",
    "\n",
    "GridSearchCV is find best one using cross validation\n",
    "\n",
    "parameters ware tested\n",
    "    n_estimator - number of trees\n",
    "    max_depth - how deep trees can go\n",
    "    min_samples_split, min_samples_leaf - to control overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a007bc42",
   "metadata": {},
   "source": [
    "2.\tRun Adaboost and GB on the given data and compare. Explain your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7246432b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy: 0.7666666666666667\n",
      "[[ 44  46]\n",
      " [ 24 186]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.49      0.56        90\n",
      "           1       0.80      0.89      0.84       210\n",
      "\n",
      "    accuracy                           0.77       300\n",
      "   macro avg       0.72      0.69      0.70       300\n",
      "weighted avg       0.76      0.77      0.76       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "ada = AdaBoostClassifier(random_state=42)\n",
    "ada.fit(x_train, y_train)\n",
    "\n",
    "y_pred_ada = ada.predict(x_test)\n",
    "\n",
    "print(\"AdaBoost Accuracy:\", accuracy_score(y_test, y_pred_ada))\n",
    "print(confusion_matrix(y_test, y_pred_ada))\n",
    "print(classification_report(y_test, y_pred_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afce7eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Accuracy: 0.7866666666666666\n",
      "[[ 47  43]\n",
      " [ 21 189]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.52      0.59        90\n",
      "           1       0.81      0.90      0.86       210\n",
      "\n",
      "    accuracy                           0.79       300\n",
      "   macro avg       0.75      0.71      0.73       300\n",
      "weighted avg       0.78      0.79      0.78       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Gradient Voosting\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "gb.fit(x_train, y_train)\n",
    "\n",
    "y_pred_gb = gb.predict(x_test)\n",
    "\n",
    "print(\"Gradient Accuracy:\", accuracy_score(y_test, y_pred_gb))\n",
    "print(confusion_matrix(y_test, y_pred_gb))\n",
    "print(classification_report(y_test, y_pred_gb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb3fac3",
   "metadata": {},
   "source": [
    "AdaBoost and Gradient ossting use as a Boosting methods. Build trees independently and boosting build models lika one ofter onother. New model tries to correct mistakes made by privious model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
